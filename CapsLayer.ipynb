{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsLayer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsdfISl1Kf/qbjM8wxOU1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoGomaa/CapsuleNetworks/blob/main/CapsLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYySx7ZOYWGH"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import initializers, layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DrHrUd-8Ym22",
        "outputId": "e65cb8d0-b67c-446a-c0bc-6bb771b8cb3e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oClGb7npYoa7"
      },
      "source": [
        "class CapsuleLayer(layers.Layer):\r\n",
        "  \"\"\"\r\n",
        "  - input shape  = [None, input_num_capsule, input_dim_capsule].\r\n",
        "  - output shape = [None, num_capsule, dim_capsule].\r\n",
        "\r\n",
        "  - param num_capsule: number of capsules in this layer.                                ( int )\r\n",
        "  - param dim_capsule: dimension of the output vectors of the capsules in this layer.   ( int )\r\n",
        "  - param routings   : number of iterations for the routing algorithm.                  ( int )\r\n",
        "  - param layer_type : 'CapsFC' or \"CapsPrimary\".                                               ( string )\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, num_capsule, dim_capsule, routings=3, layer_type=\"FC\", epsilon=1e-7, kernel_initializer='glorot_uniform', **kwargs):\r\n",
        "    super(CapsuleLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    self.num_capsule        = num_capsule\r\n",
        "    self.dim_capsule        = dim_capsule\r\n",
        "    self.routings           = routings\r\n",
        "    self.layer_type         = layer_type\r\n",
        "    self.epsilon            = epsilon\r\n",
        "    self.kernel_initializer = initializers.get(kernel_initializer)\r\n",
        "  \r\n",
        "  def build(self, input_shape):\r\n",
        "    if self.layer_type == \"CapsFC\":\r\n",
        "      assert len(input_shape) == 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\" + str(input_shape)\r\n",
        "      self.input_num_capsule = input_shape[1]\r\n",
        "      self.input_dim_capsule = input_shape[2]\r\n",
        "      # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\r\n",
        "      self.W = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, self.dim_capsule , self.input_dim_capsule],\r\n",
        "                              name='W', initializer=self.kernel_initializer, dtype=tf.float32)\r\n",
        "  \r\n",
        "  def call(self, inputs, training=None):\r\n",
        "    self.batch_size = inputs.shape[0]\r\n",
        "       \r\n",
        "    if self.layer_type == \"CapsPrimary\":\r\n",
        "      assert len(inputs.shape) == 4, \"The input Tensor should have shape=[batch_size, input_width, input_height, input_channels]\" \r\n",
        "      assert inputs.shape[1]*inputs.shape[2]*inputs.shape[3] == self.num_capsule*self.dim_capsule, \"inputs.shape[1]*inputs.shape[2]*inputs.shape[3] != self.num_capsule*self.dim_capsule\"\r\n",
        "      return tf.reshape(inputs, (-1, self.num_capsule, self.dim_capsule))\r\n",
        "    \r\n",
        "    elif self.layer_type == \"CapsFC\":\r\n",
        "      assert self.routings > 0, \"Thr number routings must be greater than 0.\"\r\n",
        "      with tf.name_scope(\"CapsuleFormation\") as scope:\r\n",
        "        u     = tf.expand_dims(tf.expand_dims(inputs, axis=-2),axis=-1)       # u.shape:     (batch_size, input_num_capsule, 1, input_dim_capsule, 1)\r\n",
        "        u_hat = tf.squeeze(tf.matmul(self.W, u))                              # u_hat.shape: (batch_size, input_num_capsule, num_capsule, dim_capsule)\r\n",
        "        \r\n",
        "      with tf.name_scope(\"DynamicRouting\") as scope:\r\n",
        "        b = tf.zeros((inputs.shape[0], self.input_num_capsule, self.num_capsule, 1))\r\n",
        "        for i in range(self.routings):\r\n",
        "          c  = tf.nn.softmax(b, axis=-2)                                      # c.shape: (batch_size, input_num_capsule, num_capsule, 1)\r\n",
        "          s  = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True)    # s.shape: (batch_size, 1, num_capsule, dim_capsule)\r\n",
        "          v  = self.__squash(s)                                               # v.shape: (batch_size, 1, num_capsule, dim_capsule)\r\n",
        "          a  = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), axis=[-1])\r\n",
        "          b += a\r\n",
        "      \r\n",
        "      return tf.squeeze(v)\r\n",
        "  \r\n",
        "  def __squash(self, s):\r\n",
        "    s_norm = tf.norm(s, axis=-1, keepdims=True)\r\n",
        "    return tf.square(s_norm)/(1 + tf.square(s_norm)) * s/(s_norm + self.epsilon)\r\n",
        "\r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\r\n",
        "  \r\n",
        "  def get_config(self):\r\n",
        "    config = {'num_capsule': self.num_capsule,\r\n",
        "              'dim_capsule': self.dim_capsule,\r\n",
        "              'routings': self.routings}\r\n",
        "    base_config = super(CapsuleLayer, self).get_config()\r\n",
        "    return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}